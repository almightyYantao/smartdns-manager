package database

import (
	"context"
	"fmt"
	"log"
	"time"

	"smartdns-manager/config"

	"github.com/ClickHouse/clickhouse-go/v2"
	"github.com/ClickHouse/clickhouse-go/v2/lib/driver"
)

var CHConn driver.Conn

// InitClickHouse åˆå§‹åŒ– ClickHouse è¿æ¥
func InitClickHouse() {
	cfg := config.GetClickHouseConfig()
	log.Printf("ğŸ”— æ­£åœ¨è¿æ¥ ClickHouse: %s:%d", cfg.Host, cfg.Port)

	// ç¬¬ä¸€æ­¥ï¼šè¿æ¥åˆ° ClickHouseï¼ˆä¸æŒ‡å®šæ•°æ®åº“ï¼‰
	conn, err := clickhouse.Open(&clickhouse.Options{
		Addr: []string{fmt.Sprintf("%s:%d", cfg.Host, cfg.Port)},
		Auth: clickhouse.Auth{
			Username: cfg.Username,
			Password: cfg.Password,
		},
		DialTimeout: 10 * time.Second,
		Compression: &clickhouse.Compression{
			Method: clickhouse.CompressionLZ4,
		},
		MaxOpenConns:    20, // å¢åŠ è¿æ¥æ•°
		MaxIdleConns:    10, // å¢åŠ ç©ºé—²è¿æ¥æ•°
		ConnMaxLifetime: time.Hour,
	})
	if err != nil {
		log.Fatal("âŒ è¿æ¥ ClickHouse å¤±è´¥:", err)
	}

	// æµ‹è¯•è¿æ¥
	ctx := context.Background()
	log.Println("âœ… ClickHouse è¿æ¥æˆåŠŸ")
	// å…³é—­åˆå§‹è¿æ¥
	conn.Close()
	CHConn, err = clickhouse.Open(&clickhouse.Options{
		Addr: []string{fmt.Sprintf("%s:%d", cfg.Host, cfg.Port)},
		Auth: clickhouse.Auth{
			Database: cfg.Database,
			Username: cfg.Username,
			Password: cfg.Password,
		},
		DialTimeout: 10 * time.Second,
		Compression: &clickhouse.Compression{
			Method: clickhouse.CompressionLZ4,
		},
		MaxOpenConns:    20,
		MaxIdleConns:    10,
		ConnMaxLifetime: time.Hour,
	})
	// æ‰§è¡Œè¿ç§»æ›¿ä»£åŸæ¥çš„ createTablesIfNotExists
	if err := runMigrations(ctx, CHConn); err != nil {
		CHConn.Close()
		log.Fatal("âŒ æ•°æ®åº“è¿ç§»å¤±è´¥:", err)
	}

	// åˆ›å»ºç´¢å¼•å’Œè§†å›¾
	if err := createIndexes(ctx, CHConn); err != nil {
		log.Printf("âš ï¸ åˆ›å»ºç´¢å¼•å¤±è´¥: %v", err)
	}

	if err := createMaterializedViews(ctx, CHConn); err != nil {
		log.Printf("âš ï¸ åˆ›å»ºç‰©åŒ–è§†å›¾å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: %v", err)
	}

	log.Printf("âœ… ClickHouse åˆå§‹åŒ–å®Œæˆ - æ•°æ®åº“: %s", cfg.Database)
}

// createIndexes åˆ›å»ºç´¢å¼•
func createIndexes(ctx context.Context, conn driver.Conn) error {
	log.Println("ğŸ”¨ åˆ›å»ºç´¢å¼•...")

	indexes := []struct {
		name string
		sql  string
	}{
		{
			name: "idx_timestamp",
			sql:  "ALTER TABLE dns_query_log ADD INDEX IF NOT EXISTS idx_timestamp (timestamp) TYPE minmax GRANULARITY 1",
		},
		{
			name: "idx_domain",
			sql:  "ALTER TABLE dns_query_log ADD INDEX IF NOT EXISTS idx_domain (domain) TYPE bloom_filter GRANULARITY 1",
		},
		{
			name: "idx_client_ip",
			sql:  "ALTER TABLE dns_query_log ADD INDEX IF NOT EXISTS idx_client_ip (client_ip) TYPE bloom_filter GRANULARITY 1",
		},
		{
			name: "idx_query_type",
			sql:  "ALTER TABLE dns_query_log ADD INDEX IF NOT EXISTS idx_query_type (query_type) TYPE set(100) GRANULARITY 1",
		},
		{
			name: "idx_node_timestamp",
			sql:  "ALTER TABLE dns_query_log ADD INDEX IF NOT EXISTS idx_node_timestamp (node_id, timestamp) TYPE minmax GRANULARITY 1",
		},
		{
			name: "idx_domain_fuzzy",
			sql:  "ALTER TABLE dns_query_log ADD INDEX IF NOT EXISTS idx_domain_fuzzy (domain) TYPE ngrambf_v1(3, 256, 2, 0) GRANULARITY 1",
		},
	}

	for _, idx := range indexes {
		log.Printf("  åˆ›å»ºç´¢å¼•: %s", idx.name)
		if err := conn.Exec(ctx, idx.sql); err != nil {
			log.Printf("  âš ï¸ åˆ›å»ºç´¢å¼• %s å¤±è´¥: %v", idx.name, err)
		} else {
			log.Printf("  âœ… ç´¢å¼• %s åˆ›å»ºæˆåŠŸ", idx.name)
		}
	}

	return nil
}

// createMaterializedViews åˆ›å»ºç‰©åŒ–è§†å›¾ï¼ˆç”¨äºåŠ é€Ÿç»Ÿè®¡æŸ¥è¯¢ï¼‰
func createMaterializedViews(ctx context.Context, conn driver.Conn) error {
	log.Println("ğŸ”¨ åˆ›å»ºç‰©åŒ–è§†å›¾...")

	// 1. æŒ‰å°æ—¶ç»Ÿè®¡çš„ç‰©åŒ–è§†å›¾
	hourlyStatsSQL := `
    CREATE MATERIALIZED VIEW IF NOT EXISTS dns_stats_hourly
    ENGINE = AggregatingMergeTree()
    PARTITION BY toYYYYMM(date)
    ORDER BY (date, hour, node_id, domain)
    TTL date + INTERVAL 30 DAY
    AS SELECT
        toDate(timestamp) as date,
        toHour(timestamp) as hour,
        node_id,
        domain,
        countState() as query_count,
        avgState(time_ms) as avg_time_ms,
        maxState(time_ms) as max_time_ms,
        minState(time_ms) as min_time_ms,
        uniqState(client_ip) as unique_clients
    FROM dns_query_log
    GROUP BY date, hour, node_id, domain
    `

	if err := conn.Exec(ctx, hourlyStatsSQL); err != nil {
		log.Printf("âš ï¸ åˆ›å»º dns_stats_hourly è§†å›¾å¤±è´¥: %v", err)
	} else {
		log.Println("âœ… dns_stats_hourly è§†å›¾åˆ›å»ºæˆåŠŸ")
	}

	// 2. çƒ­é—¨åŸŸåç»Ÿè®¡çš„ç‰©åŒ–è§†å›¾
	topDomainsSQL := `
    CREATE MATERIALIZED VIEW IF NOT EXISTS dns_top_domains
    ENGINE = AggregatingMergeTree()
    PARTITION BY toYYYYMM(date)
    ORDER BY (date, node_id, domain)
    TTL date + INTERVAL 30 DAY
    AS SELECT
        toDate(timestamp) as date,
        node_id,
        domain,
        countState() as query_count,
        uniqState(client_ip) as unique_clients,
        avgState(time_ms) as avg_response_time
    FROM dns_query_log
    GROUP BY date, node_id, domain
    `

	if err := conn.Exec(ctx, topDomainsSQL); err != nil {
		log.Printf("âš ï¸ åˆ›å»º dns_top_domains è§†å›¾å¤±è´¥: %v", err)
	} else {
		log.Println("âœ… dns_top_domains è§†å›¾åˆ›å»ºæˆåŠŸ")
	}

	// 3. å®¢æˆ·ç«¯ç»Ÿè®¡çš„ç‰©åŒ–è§†å›¾
	clientStatsSQL := `
    CREATE MATERIALIZED VIEW IF NOT EXISTS dns_client_stats
    ENGINE = AggregatingMergeTree()
    PARTITION BY toYYYYMM(date)
    ORDER BY (date, node_id, client_ip)
    TTL date + INTERVAL 30 DAY
    AS SELECT
        toDate(timestamp) as date,
        node_id,
        client_ip,
        countState() as query_count,
        uniqState(domain) as unique_domains,
        avgState(time_ms) as avg_response_time
    FROM dns_query_log
    GROUP BY date, node_id, client_ip
    `

	if err := conn.Exec(ctx, clientStatsSQL); err != nil {
		log.Printf("âš ï¸ åˆ›å»º dns_client_stats è§†å›¾å¤±è´¥: %v", err)
	} else {
		log.Println("âœ… dns_client_stats è§†å›¾åˆ›å»ºæˆåŠŸ")
	}

	// 4. æ¯æ—¥æ‘˜è¦ç»Ÿè®¡ - æ–°å¢
	dailySummarySQL := `
    CREATE MATERIALIZED VIEW IF NOT EXISTS dns_daily_summary
    ENGINE = ReplacingMergeTree()
    PARTITION BY toYYYYMM(date)
    ORDER BY (date, node_id)
    TTL date + INTERVAL 365 DAY
    AS SELECT
        toDate(timestamp) as date,
        node_id,
        count() as total_queries,
        uniqExact(domain) as unique_domains,
        uniqExact(client_ip) as unique_clients,
        avg(time_ms) as avg_response_time,
        quantile(0.95)(time_ms) as p95_response_time,
        countIf(time_ms > 1000) as slow_queries
    FROM dns_query_log
    GROUP BY date, node_id
    `

	if err := conn.Exec(ctx, dailySummarySQL); err != nil {
		log.Printf("âš ï¸ åˆ›å»º dns_daily_summary è§†å›¾å¤±è´¥: %v", err)
	} else {
		log.Println("âœ… dns_daily_summary è§†å›¾åˆ›å»ºæˆåŠŸ")
	}

	return nil
}
