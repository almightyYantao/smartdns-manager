package services

import (
	"bufio"
	"context"
	"fmt"
	"log"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"time"

	"smartdns-manager/models"

	"golang.org/x/crypto/ssh"
	"gorm.io/gorm"
)

// NodeMonitor å•ä¸ªèŠ‚ç‚¹çš„ç›‘æ§å™¨
type NodeMonitor struct {
	nodeID      uint
	node        *models.Node
	sshClient   *SSHClient
	ctx         context.Context
	cancel      context.CancelFunc
	isRunning   bool
	logRegex    *regexp.Regexp
	batchBuffer []*models.DNSLog
	mu          sync.Mutex
}

// LogMonitorService æ—¥å¿—ç›‘æ§æœåŠ¡ï¼ˆç®¡ç†æ‰€æœ‰èŠ‚ç‚¹ç›‘æ§ï¼‰
type LogMonitorService struct {
	db          *gorm.DB
	monitors    map[uint]*NodeMonitor // nodeID -> monitor
	mu          sync.RWMutex
	batchSize   int
	flushTicker *time.Ticker
	logRegex    *regexp.Regexp
}

// NewLogMonitorService åˆ›å»ºæ—¥å¿—ç›‘æ§æœåŠ¡
func NewLogMonitorService(db *gorm.DB) *LogMonitorService {
	// ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
	logRegex := regexp.MustCompile(`\[([^\]]+)\]\s+(\S+)\s+query\s+(\S+),\s+type\s+(\d+),\s+time\s+(\d+)ms,\s+speed:\s+([-\d.]+)ms,\s+result\s*(.*)`)

	service := &LogMonitorService{
		db:          db,
		monitors:    make(map[uint]*NodeMonitor),
		batchSize:   100,
		flushTicker: time.NewTicker(5 * time.Second),
		logRegex:    logRegex,
	}

	// å¯åŠ¨æ‰¹é‡åˆ·æ–°åç¨‹
	go service.flushLoop()

	return service
}

// StartNodeMonitor å¯åŠ¨æŒ‡å®šèŠ‚ç‚¹çš„æ—¥å¿—ç›‘æ§
func (s *LogMonitorService) StartNodeMonitor(nodeID uint) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	// æ£€æŸ¥æ˜¯å¦å·²åœ¨è¿è¡Œ
	if monitor, exists := s.monitors[nodeID]; exists && monitor.isRunning {
		return fmt.Errorf("èŠ‚ç‚¹ %d çš„ç›‘æ§å·²åœ¨è¿è¡Œ", nodeID)
	}

	// è·å–èŠ‚ç‚¹ä¿¡æ¯
	var node models.Node
	if err := s.db.First(&node, nodeID).Error; err != nil {
		return fmt.Errorf("èŠ‚ç‚¹ä¸å­˜åœ¨: %w", err)
	}

	// åˆ›å»º SSH å®¢æˆ·ç«¯
	sshClient, err := NewSSHClient(&node)
	if err != nil {
		return fmt.Errorf("SSHè¿æ¥å¤±è´¥: %w", err)
	}

	// æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	logPath := node.LogPath
	if logPath == "" {
		logPath = "/var/log/smartdns/smartdns.log"
	}

	_, err = sshClient.ExecuteCommand(fmt.Sprintf("test -f %s && echo 'exists'", logPath))
	if err != nil {
		sshClient.Close()
		return fmt.Errorf("æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: %s", logPath)
	}

	// åˆ›å»ºç›‘æ§å™¨
	ctx, cancel := context.WithCancel(context.Background())
	monitor := &NodeMonitor{
		nodeID:      nodeID,
		node:        &node,
		sshClient:   sshClient,
		ctx:         ctx,
		cancel:      cancel,
		isRunning:   true,
		logRegex:    s.logRegex,
		batchBuffer: make([]*models.DNSLog, 0, s.batchSize),
	}

	s.monitors[nodeID] = monitor

	// å¯åŠ¨ç›‘æ§åç¨‹
	go monitor.startMonitoring(s.db, s.batchSize)

	// æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
	s.db.Model(&models.Node{}).Where("id = ?", nodeID).Updates(map[string]interface{}{
		"log_monitor_enabled": true,
	})

	log.Printf("å·²å¯åŠ¨èŠ‚ç‚¹ %d (%s) çš„æ—¥å¿—ç›‘æ§", nodeID, node.Name)
	return nil
}

// StopNodeMonitor åœæ­¢æŒ‡å®šèŠ‚ç‚¹çš„æ—¥å¿—ç›‘æ§
func (s *LogMonitorService) StopNodeMonitor(nodeID uint) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	monitor, exists := s.monitors[nodeID]
	if !exists || !monitor.isRunning {
		return fmt.Errorf("èŠ‚ç‚¹ %d çš„ç›‘æ§æœªè¿è¡Œ", nodeID)
	}

	// åœæ­¢ç›‘æ§
	monitor.stop(s.db)
	delete(s.monitors, nodeID)

	// æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
	s.db.Model(&models.Node{}).Where("id = ?", nodeID).Updates(map[string]interface{}{
		"log_monitor_enabled": false,
	})

	log.Printf("å·²åœæ­¢èŠ‚ç‚¹ %d çš„æ—¥å¿—ç›‘æ§", nodeID)
	return nil
}

// GetNodeMonitorStatus è·å–èŠ‚ç‚¹ç›‘æ§çŠ¶æ€
func (s *LogMonitorService) GetNodeMonitorStatus(nodeID uint) (bool, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	monitor, exists := s.monitors[nodeID]
	if !exists {
		return false, nil
	}
	return monitor.isRunning, nil
}

// StopAll åœæ­¢æ‰€æœ‰ç›‘æ§
func (s *LogMonitorService) StopAll() {
	s.mu.Lock()
	defer s.mu.Unlock()

	for nodeID, monitor := range s.monitors {
		monitor.stop(s.db)
		log.Printf("å·²åœæ­¢èŠ‚ç‚¹ %d çš„ç›‘æ§", nodeID)
	}
	s.monitors = make(map[uint]*NodeMonitor)
	s.flushTicker.Stop()
}

// flushLoop å®šæ—¶åˆ·æ–°æ‰€æœ‰èŠ‚ç‚¹çš„æ‰¹é‡æ•°æ®
func (s *LogMonitorService) flushLoop() {
	for range s.flushTicker.C {
		s.mu.RLock()
		monitors := make([]*NodeMonitor, 0, len(s.monitors))
		for _, monitor := range s.monitors {
			monitors = append(monitors, monitor)
		}
		s.mu.RUnlock()

		for _, monitor := range monitors {
			monitor.flushBatch(s.db)
		}
	}
}

// startMonitoring å¼€å§‹ç›‘æ§ï¼ˆåœ¨ SSH ä¸Šæ‰§è¡Œ tail -fï¼‰
func (m *NodeMonitor) startMonitoring(db *gorm.DB, batchSize int) {
	defer func() {
		m.isRunning = false
		m.sshClient.Close()
		log.Printf("ğŸ›‘ èŠ‚ç‚¹ %d ç›‘æ§å·²åœæ­¢", m.nodeID)
	}()

	logPath := m.node.LogPath
	if logPath == "" {
		logPath = "/var/log/audit/audit.log"
	}

	// ä½¿ç”¨ tail -f -n 0 åªè¯»å–æ–°å¢æ—¥å¿—
	cmd := fmt.Sprintf("tail -f -n 0 %s", logPath)

	log.Printf("ğŸ”„ æ‰§è¡Œå‘½ä»¤: %s", cmd)

	session, err := m.sshClient.client.NewSession()
	if err != nil {
		log.Printf("âŒ åˆ›å»ºSSHä¼šè¯å¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
		return
	}
	defer session.Close()

	stdout, err := session.StdoutPipe()
	if err != nil {
		log.Printf("âŒ è·å–æ ‡å‡†è¾“å‡ºå¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
		return
	}

	if err := session.Start(cmd); err != nil {
		log.Printf("âŒ æ‰§è¡Œå‘½ä»¤å¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
		return
	}

	log.Printf("âœ… å¼€å§‹ç›‘æ§èŠ‚ç‚¹ %d çš„æ—¥å¿—", m.nodeID)

	scanner := bufio.NewScanner(stdout)
	lineCount := 0

	for {
		select {
		case <-m.ctx.Done():
			log.Printf("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å· (èŠ‚ç‚¹%d)", m.nodeID)
			session.Signal(ssh.SIGTERM)
			return
		default:
			if scanner.Scan() {
				line := strings.TrimSpace(scanner.Text())
				lineCount++

				// æ¯å¤„ç† 10 è¡Œæ‰“å°ä¸€æ¬¡æ—¥å¿—
				if lineCount%10 == 0 {
					log.Printf("ğŸ“Š èŠ‚ç‚¹ %d å·²å¤„ç† %d è¡Œæ—¥å¿—", m.nodeID, lineCount)
				}

				if dnsLog := m.parseLine(line); dnsLog != nil {
					dnsLog.NodeID = m.nodeID
					m.addToBatch(dnsLog)

					// è¾¾åˆ°æ‰¹é‡å¤§å°ï¼Œç«‹å³åˆ·æ–°
					if len(m.batchBuffer) >= batchSize {
						log.Printf("ğŸ’¾ èŠ‚ç‚¹ %d æ‰¹é‡ç¼“å†²åŒºå·²æ»¡ (%d æ¡)ï¼Œå¼€å§‹å†™å…¥", m.nodeID, len(m.batchBuffer))
						m.flushBatch(db)
					}
				} else {
					// è§£æå¤±è´¥æ—¶æ‰“å°æ ·æœ¬
					if lineCount <= 5 {
						log.Printf("âš ï¸ è§£æå¤±è´¥ (èŠ‚ç‚¹%d): %s", m.nodeID, line)
					}
				}
			}

			if err := scanner.Err(); err != nil {
				log.Printf("âŒ è¯»å–æ—¥å¿—å‡ºé”™ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
				return
			}
		}
	}
}

// stop åœæ­¢ç›‘æ§
func (m *NodeMonitor) stop(db *gorm.DB) {
	m.cancel()
	m.flushBatch(db) // åˆ·æ–°å‰©ä½™æ•°æ®
	m.isRunning = false
}

// addToBatch æ·»åŠ åˆ°æ‰¹é‡ç¼“å†²åŒº
func (m *NodeMonitor) addToBatch(dnsLog *models.DNSLog) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.batchBuffer = append(m.batchBuffer, dnsLog)
}

// flushBatch åˆ·æ–°æ‰¹é‡æ•°æ®åˆ°æ•°æ®åº“
func (m *NodeMonitor) flushBatch(db *gorm.DB) {
	m.mu.Lock()
	defer m.mu.Unlock()

	if len(m.batchBuffer) == 0 {
		return
	}

	batchCount := len(m.batchBuffer)
	log.Printf("ğŸ’¾ å‡†å¤‡å†™å…¥ %d æ¡æ—¥å¿—åˆ°æ•°æ®åº“ (èŠ‚ç‚¹%d)", batchCount, m.nodeID)

	startTime := time.Now()
	if err := db.CreateInBatches(m.batchBuffer, 100).Error; err != nil {
		log.Printf("âŒ æ’å…¥DNSæ—¥å¿—å¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
	} else {
		duration := time.Since(startTime)
		log.Printf("âœ… æˆåŠŸæ’å…¥ %d æ¡DNSæ—¥å¿— (èŠ‚ç‚¹%d), è€—æ—¶: %v", batchCount, m.nodeID, duration)
	}

	m.batchBuffer = make([]*models.DNSLog, 0, 100)
}

// parseLine è§£ææ—¥å¿—è¡Œ
func (m *NodeMonitor) parseLine(line string) *models.DNSLog {
	if line == "" {
		return nil
	}

	matches := m.logRegex.FindStringSubmatch(line)
	if matches == nil || len(matches) < 8 {
		return nil
	}

	// è§£ææ—¶é—´æˆ³ - æŒ‡å®šä½¿ç”¨ UTC æ—¶åŒº
	var timestamp time.Time
	var err error

	// å°è¯•è§£æå¸¦æ¯«ç§’çš„æ ¼å¼
	timestamp, err = time.ParseInLocation("2006-01-02 15:04:05,000", matches[1], time.UTC)
	if err != nil {
		// å¦‚æœå¤±è´¥ï¼Œå°è¯•ä¸å¸¦æ¯«ç§’çš„æ ¼å¼
		timestamp, err = time.ParseInLocation("2006-01-02 15:04:05", matches[1][:19], time.UTC)
		if err != nil {
			log.Printf("âš ï¸ è§£ææ—¶é—´å¤±è´¥: %s, error: %v", matches[1], err)
			return nil
		}
	}

	queryType, _ := strconv.Atoi(matches[4])
	timeMs, _ := strconv.Atoi(matches[5])
	speedMs, _ := strconv.ParseFloat(matches[6], 64)

	resultStr := strings.TrimSpace(matches[7])
	var resultIPs []string
	if resultStr != "" {
		resultIPs = strings.Split(resultStr, ",")
		for i := range resultIPs {
			resultIPs[i] = strings.TrimSpace(resultIPs[i])
		}
	}

	return &models.DNSLog{
		Timestamp: timestamp,
		ClientIP:  matches[2],
		Domain:    matches[3],
		QueryType: queryType,
		TimeMs:    timeMs,
		SpeedMs:   speedMs,
		Result:    resultStr,
		ResultIPs: strings.Join(resultIPs, ","),
		IPCount:   len(resultIPs),
		RawLog:    line,
		CreatedAt: time.Now(),
	}
}

// æŸ¥è¯¢æ–¹æ³•

// GetLogs è·å–æ—¥å¿—åˆ—è¡¨ï¼ˆæ”¯æŒæŒ‰èŠ‚ç‚¹è¿‡æ»¤ï¼‰
func (s *LogMonitorService) GetLogs(page, pageSize int, filters map[string]interface{}) ([]models.DNSLog, int64, error) {
	var logs []models.DNSLog
	var total int64

	query := s.db.Model(&models.DNSLog{}).Preload("Node")

	// åº”ç”¨è¿‡æ»¤æ¡ä»¶
	if nodeID, ok := filters["node_id"]; ok && nodeID != nil {
		query = query.Where("node_id = ?", nodeID)
	}
	if clientIP, ok := filters["client_ip"]; ok && clientIP != "" {
		query = query.Where("client_ip = ?", clientIP)
	}
	if domain, ok := filters["domain"]; ok && domain != "" {
		query = query.Where("domain LIKE ?", "%"+domain.(string)+"%")
	}
	if queryType, ok := filters["query_type"]; ok {
		query = query.Where("query_type = ?", queryType)
	}
	if startTime, ok := filters["start_time"]; ok {
		query = query.Where("timestamp >= ?", startTime)
	}
	if endTime, ok := filters["end_time"]; ok {
		query = query.Where("timestamp <= ?", endTime)
	}

	query.Count(&total)

	offset := (page - 1) * pageSize
	err := query.Order("timestamp DESC").
		Offset(offset).
		Limit(pageSize).
		Find(&logs).Error

	return logs, total, err
}

// GetNodeStats è·å–èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯
func (s *LogMonitorService) GetNodeStats(nodeID uint, startTime, endTime time.Time) (*models.DNSLogStats, error) {
	stats := &models.DNSLogStats{
		TopDomains:  make([]models.DomainStat, 0),
		TopClients:  make([]models.ClientStat, 0),
		HourlyStats: make([]models.HourlyStat, 0),
	}

	// æ€»æŸ¥è¯¢æ•°
	var totalQueries int64
	s.db.Model(&models.DNSLog{}).
		Where("node_id = ? AND timestamp BETWEEN ? AND ?", nodeID, startTime, endTime).
		Count(&totalQueries)
	stats.TotalQueries = totalQueries

	// å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç›´æ¥è¿”å›ç©ºç»Ÿè®¡
	if totalQueries == 0 {
		log.Printf("âš ï¸ èŠ‚ç‚¹ %d åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ—¥å¿—æ•°æ®", nodeID)
		return stats, nil
	}

	// å”¯ä¸€å®¢æˆ·ç«¯æ•°
	var uniqueClients int64
	s.db.Model(&models.DNSLog{}).
		Where("node_id = ? AND timestamp BETWEEN ? AND ?", nodeID, startTime, endTime).
		Distinct("client_ip").
		Count(&uniqueClients)
	stats.UniqueClients = uniqueClients

	// å”¯ä¸€åŸŸåæ•°
	var uniqueDomains int64
	s.db.Model(&models.DNSLog{}).
		Where("node_id = ? AND timestamp BETWEEN ? AND ?", nodeID, startTime, endTime).
		Distinct("domain").
		Count(&uniqueDomains)
	stats.UniqueDomains = uniqueDomains

	// å¹³å‡æŸ¥è¯¢æ—¶é—´ - å¤„ç†ç©ºå€¼
	var avgQueryTime *float64 // ä½¿ç”¨æŒ‡é’ˆ
	s.db.Model(&models.DNSLog{}).
		Where("node_id = ? AND timestamp BETWEEN ? AND ?", nodeID, startTime, endTime).
		Select("AVG(time_ms)").
		Scan(&avgQueryTime)
	if avgQueryTime != nil {
		stats.AvgQueryTime = *avgQueryTime
	} else {
		stats.AvgQueryTime = 0
	}

	// çƒ­é—¨åŸŸåï¼ˆTop 10ï¼‰
	type domainCount struct {
		Domain string
		Count  int64
	}
	var topDomains []domainCount
	s.db.Model(&models.DNSLog{}).
		Select("domain, COUNT(*) as count").
		Where("node_id = ? AND timestamp BETWEEN ? AND ?", nodeID, startTime, endTime).
		Group("domain").
		Order("count DESC").
		Limit(10).
		Scan(&topDomains)

	for _, item := range topDomains {
		stats.TopDomains = append(stats.TopDomains, models.DomainStat{
			Domain: item.Domain,
			Count:  item.Count,
		})
	}

	// çƒ­é—¨å®¢æˆ·ç«¯ï¼ˆTop 10ï¼‰
	type clientCount struct {
		ClientIP string
		Count    int64
	}
	var topClients []clientCount
	s.db.Model(&models.DNSLog{}).
		Select("client_ip, COUNT(*) as count").
		Where("node_id = ? AND timestamp BETWEEN ? AND ?", nodeID, startTime, endTime).
		Group("client_ip").
		Order("count DESC").
		Limit(10).
		Scan(&topClients)

	for _, item := range topClients {
		stats.TopClients = append(stats.TopClients, models.ClientStat{
			ClientIP: item.ClientIP,
			Count:    item.Count,
		})
	}

	// æŒ‰å°æ—¶ç»Ÿè®¡
	type hourlyCount struct {
		Hour  int
		Count int64
	}
	var hourlyStats []hourlyCount

	// SQLite ä½¿ç”¨ strftime å‡½æ•°æå–å°æ—¶
	s.db.Model(&models.DNSLog{}).
		Select("CAST(strftime('%H', timestamp) AS INTEGER) as hour, COUNT(*) as count").
		Where("node_id = ? AND timestamp BETWEEN ? AND ?", nodeID, startTime, endTime).
		Group("hour").
		Order("hour").
		Scan(&hourlyStats)

	for _, item := range hourlyStats {
		stats.HourlyStats = append(stats.HourlyStats, models.HourlyStat{
			Hour:  item.Hour,
			Count: item.Count,
		})
	}

	return stats, nil
}

// CleanNodeLogs æ¸…ç†æŒ‡å®šèŠ‚ç‚¹çš„æ—§æ—¥å¿—
func (s *LogMonitorService) CleanNodeLogs(nodeID uint, days int) error {
	cutoffTime := time.Now().AddDate(0, 0, -days)
	result := s.db.Where("node_id = ? AND timestamp < ?", nodeID, cutoffTime).
		Delete(&models.DNSLog{})

	if result.Error != nil {
		return result.Error
	}

	log.Printf("æ¸…ç†èŠ‚ç‚¹ %d çš„ %d æ¡æ—§æ—¥å¿—", nodeID, result.RowsAffected)
	return nil
}
