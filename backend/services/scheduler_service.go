package services

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"sync"
	"time"

	"github.com/robfig/cron/v3"
	"gorm.io/gorm"
	"gorm.io/gorm/logger"

	"smartdns-manager/config"
	"smartdns-manager/models"
)

// SchedulerService å®šæ—¶ä»»åŠ¡è°ƒåº¦æœåŠ¡
type SchedulerService struct {
	db        *gorm.DB
	config    *config.Config
	cron      *cron.Cron
	s3        *S3Service
	mutex     sync.RWMutex
	running   bool
	taskExecs map[uint]context.CancelFunc // æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡

	// å­æœåŠ¡
	dbBackup     *DatabaseBackupService
	nodeBackup   *NodeBackupService
	logCleanup   *LogCleanupService
	telemetry    *TelemetryService
	customScript *CustomScriptService
}

// NewSchedulerService åˆ›å»ºè°ƒåº¦æœåŠ¡
func NewSchedulerService(db *gorm.DB, config *config.Config, s3 *S3Service) (*SchedulerService, error) {
	scheduler := &SchedulerService{
		db:        db,
		config:    config,
		s3:        s3,
		cron:      cron.New(cron.WithSeconds()),
		taskExecs: make(map[uint]context.CancelFunc),
	}

	// åˆå§‹åŒ–å­æœåŠ¡
	dbBackupService := NewDatabaseBackupService(db, s3)
	scheduler.dbBackup = dbBackupService

	nodeBackupService, err := NewNodeBackupService(db, config, s3)
	if err != nil {
		return nil, fmt.Errorf("åˆå§‹åŒ–èŠ‚ç‚¹å¤‡ä»½æœåŠ¡å¤±è´¥: %w", err)
	}
	scheduler.nodeBackup = nodeBackupService

	logCleanupService, err := NewLogCleanupService(db, config)
	if err != nil {
		return nil, fmt.Errorf("åˆå§‹åŒ–æ—¥å¿—æ¸…ç†æœåŠ¡å¤±è´¥: %w", err)
	}
	scheduler.logCleanup = logCleanupService

	telemetryService, err := NewTelemetryService(db, config)
	if err != nil {
		return nil, fmt.Errorf("åˆå§‹åŒ–é¥æµ‹æœåŠ¡å¤±è´¥: %w", err)
	}
	scheduler.telemetry = telemetryService

	customScriptService, err := NewCustomScriptService(db, config)
	if err != nil {
		return nil, fmt.Errorf("åˆå§‹åŒ–è‡ªå®šä¹‰è„šæœ¬æœåŠ¡å¤±è´¥: %w", err)
	}
	scheduler.customScript = customScriptService

	return scheduler, nil
}

// Start å¯åŠ¨è°ƒåº¦æœåŠ¡
func (s *SchedulerService) Start() error {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	if s.running {
		return fmt.Errorf("è°ƒåº¦æœåŠ¡å·²ç»åœ¨è¿è¡Œ")
	}

	// åˆå§‹åŒ–é»˜è®¤ä»»åŠ¡
	if err := s.initializeDefaultTasks(); err != nil {
		log.Printf("âš ï¸ åˆå§‹åŒ–é»˜è®¤ä»»åŠ¡å¤±è´¥: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå…è®¸ç³»ç»Ÿç»§ç»­å¯åŠ¨
	}

	// åŠ è½½å¹¶æ³¨å†Œæ‰€æœ‰ä»»åŠ¡
	if err := s.loadTasks(); err != nil {
		return fmt.Errorf("åŠ è½½ä»»åŠ¡å¤±è´¥: %w", err)
	}

	s.cron.Start()
	s.running = true

	log.Printf("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦æœåŠ¡å¯åŠ¨æˆåŠŸ")
	return nil
}

// Stop åœæ­¢è°ƒåº¦æœåŠ¡
func (s *SchedulerService) Stop() {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	if !s.running {
		return
	}

	// åœæ­¢cronè°ƒåº¦å™¨
	ctx := s.cron.Stop()
	<-ctx.Done()

	// å–æ¶ˆæ‰€æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡
	for taskID, cancel := range s.taskExecs {
		log.Printf("ğŸ›‘ å–æ¶ˆæ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡: %d", taskID)
		cancel()
	}

	s.running = false
	log.Printf("ğŸ›‘ å®šæ—¶ä»»åŠ¡è°ƒåº¦æœåŠ¡å·²åœæ­¢")
}

// loadTasks åŠ è½½æ‰€æœ‰å¯ç”¨çš„ä»»åŠ¡
func (s *SchedulerService) loadTasks() error {
	var tasks []models.ScheduledTask
	if err := s.db.Where("enabled = ?", true).Find(&tasks).Error; err != nil {
		return fmt.Errorf("æŸ¥è¯¢ä»»åŠ¡å¤±è´¥: %w", err)
	}

	log.Printf("ğŸ”„ å¼€å§‹åŠ è½½å®šæ—¶ä»»åŠ¡ï¼Œå…±æ‰¾åˆ° %d ä¸ªå¯ç”¨çš„ä»»åŠ¡", len(tasks))

	successCount := 0
	for _, task := range tasks {
		if err := s.addTaskToCron(task); err != nil {
			log.Printf("âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥ [%s]: %v", task.Name, err)
			continue
		}
		log.Printf("ğŸ“… æ·»åŠ å®šæ—¶ä»»åŠ¡: %s (%s)", task.Name, task.CronExpr)
		successCount++
	}

	log.Printf("âœ… ä»»åŠ¡åŠ è½½å®Œæˆ: æˆåŠŸ %d/%d", successCount, len(tasks))
	return nil
}

// addTaskToCron æ·»åŠ ä»»åŠ¡åˆ°cronè°ƒåº¦å™¨
func (s *SchedulerService) addTaskToCron(task models.ScheduledTask) error {
	entryID, err := s.cron.AddFunc(task.CronExpr, func() {
		s.executeTask(task)
	})
	if err != nil {
		return err
	}

	// è·å–ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
	entries := s.cron.Entries()
	for _, entry := range entries {
		if entry.ID == entryID {
			nextRun := entry.Next
			// æ›´æ–°ä»»åŠ¡çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
			s.db.Model(&task).Update("next_run_at", &nextRun)
			break
		}
	}

	return nil
}

// executeTask æ‰§è¡Œä»»åŠ¡
func (s *SchedulerService) executeTask(task models.ScheduledTask) {
	s.mutex.Lock()
	// æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²åœ¨æ‰§è¡Œ
	if _, exists := s.taskExecs[task.ID]; exists {
		log.Printf("âš ï¸ ä»»åŠ¡ [%s] æ­£åœ¨æ‰§è¡Œä¸­ï¼Œè·³è¿‡æœ¬æ¬¡è°ƒåº¦", task.Name)
		s.mutex.Unlock()
		return
	}

	// åˆ›å»ºå¯å–æ¶ˆçš„ä¸Šä¸‹æ–‡
	ctx, cancel := context.WithCancel(context.Background())
	s.taskExecs[task.ID] = cancel
	s.mutex.Unlock()

	// æ‰§è¡Œå®Œæˆåæ¸…ç†
	defer func() {
		s.mutex.Lock()
		delete(s.taskExecs, task.ID)
		s.mutex.Unlock()
	}()

	// åˆ›å»ºæ‰§è¡Œè®°å½•
	execution := &models.TaskExecution{
		TaskID:    task.ID,
		Status:    models.TaskStatusRunning,
		StartedAt: time.Now(),
	}

	if err := s.db.Create(execution).Error; err != nil {
		log.Printf("âŒ åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®°å½•å¤±è´¥ [%s]: %v", task.Name, err)
		return
	}

	log.Printf("ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: %s", task.Name)

	// æ‰§è¡Œå…·ä½“ä»»åŠ¡
	var err error
	var output string

	switch task.Type {
	case models.TaskTypeDBBackup:
		output, err = s.executeDBBackup(ctx, task)
	case models.TaskTypeNodeBackup:
		output, err = s.executeNodeBackup(ctx, task)
	case models.TaskTypeLogCleanup:
		output, err = s.executeLogCleanup(ctx, task)
	case models.TaskTypeTelemetry:
		output, err = s.executeTelemetry(ctx, task)
	case models.TaskTypeCustomScript:
		output, err = s.executeCustomScript(ctx, task)
	default:
		err = fmt.Errorf("æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: %s", task.Type)
	}

	// æ›´æ–°æ‰§è¡Œè®°å½•
	endTime := time.Now()
	duration := endTime.Sub(execution.StartedAt).Milliseconds()

	updates := map[string]interface{}{
		"ended_at": &endTime,
		"duration": duration,
		"output":   output,
	}

	if err != nil {
		updates["status"] = models.TaskStatusFailed
		updates["error"] = err.Error()
		log.Printf("âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ [%s]: %v", task.Name, err)
	} else {
		updates["status"] = models.TaskStatusSuccess
		log.Printf("âœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ [%s]: è€—æ—¶%dms", task.Name, duration)
	}

	// æ›´æ–°æ‰§è¡Œè®°å½•
	if err := s.db.Model(execution).Updates(updates).Error; err != nil {
		log.Printf("âŒ æ›´æ–°ä»»åŠ¡æ‰§è¡Œè®°å½•å¤±è´¥: %v", err)
	}

	// æ›´æ–°ä»»åŠ¡çŠ¶æ€
	taskUpdates := map[string]interface{}{
		"last_run_at": &endTime,
		"last_status": updates["status"],
		"run_count":   gorm.Expr("run_count + 1"),
	}

	if err == nil {
		taskUpdates["success_count"] = gorm.Expr("success_count + 1")
		taskUpdates["last_error"] = ""
	} else {
		taskUpdates["last_error"] = err.Error()
	}

	if err := s.db.Model(&task).Updates(taskUpdates).Error; err != nil {
		log.Printf("âŒ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: %v", err)
	}
}

// executeDBBackup æ‰§è¡Œæ•°æ®åº“å¤‡ä»½ä»»åŠ¡
func (s *SchedulerService) executeDBBackup(ctx context.Context, task models.ScheduledTask) (string, error) {
	var config models.DBBackupConfig
	if err := json.Unmarshal([]byte(task.Config), &config); err != nil {
		return "", fmt.Errorf("è§£æä»»åŠ¡é…ç½®å¤±è´¥: %w", err)
	}

	// åˆ›å»ºå¤‡ä»½é…ç½®
	backupConfig := models.BackupConfig{
		Name:               fmt.Sprintf("scheduled_backup_%s", time.Now().Format("20060102_150405")),
		Enabled:            true,
		BackupType:         "database",
		Schedule:           task.CronExpr,
		RetentionDays:      config.RetentionDays,
		S3Enabled:          true,
		S3AccessKey:        config.S3Config.AccessKey,
		S3SecretKey:        config.S3Config.SecretKey,
		S3Region:           config.S3Config.Region,
		S3Bucket:           config.S3Config.Bucket,
		S3Endpoint:         config.S3Config.Endpoint,
		S3Prefix:           config.S3Config.Prefix,
		CompressionEnabled: config.Compression,
		EncryptionEnabled:  config.Encryption,
	}

	// åˆ›å»ºå¤‡ä»½å†å²è®°å½•
	history := &models.BackupHistory{
		ConfigID:   0, // ä¸´æ—¶é…ç½®ï¼Œæ— éœ€ä¿å­˜åˆ°æ•°æ®åº“
		BackupType: "database",
		Status:     "running",
		StartedAt:  time.Now(),
	}

	// æ‰§è¡Œå¤‡ä»½
	err := s.dbBackup.performBackup(ctx, &backupConfig, history)
	if err != nil {
		return "", err
	}

	return fmt.Sprintf("æ•°æ®åº“å¤‡ä»½æˆåŠŸ: %s (å¤§å°: %d bytes)", history.FileName, history.FileSize), nil
}

// executeNodeBackup æ‰§è¡ŒèŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡
func (s *SchedulerService) executeNodeBackup(ctx context.Context, task models.ScheduledTask) (string, error) {
	var config models.NodeBackupConfig
	if err := json.Unmarshal([]byte(task.Config), &config); err != nil {
		return "", fmt.Errorf("è§£æä»»åŠ¡é…ç½®å¤±è´¥: %w", err)
	}

	return s.nodeBackup.BackupNodes(ctx, config)
}

// executeLogCleanup æ‰§è¡Œæ—¥å¿—æ¸…ç†ä»»åŠ¡
func (s *SchedulerService) executeLogCleanup(ctx context.Context, task models.ScheduledTask) (string, error) {
	var config models.LogCleanupConfig
	if err := json.Unmarshal([]byte(task.Config), &config); err != nil {
		return "", fmt.Errorf("è§£æä»»åŠ¡é…ç½®å¤±è´¥: %w", err)
	}

	return s.logCleanup.CleanupLogs(ctx, config)
}

// executeTelemetry æ‰§è¡Œé¥æµ‹ä»»åŠ¡
func (s *SchedulerService) executeTelemetry(ctx context.Context, task models.ScheduledTask) (string, error) {
	var config models.TelemetryConfig
	if err := json.Unmarshal([]byte(task.Config), &config); err != nil {
		return "", fmt.Errorf("è§£æä»»åŠ¡é…ç½®å¤±è´¥: %w", err)
	}

	return s.telemetry.CheckTargets(ctx, config)
}

// executeCustomScript æ‰§è¡Œè‡ªå®šä¹‰è„šæœ¬ä»»åŠ¡
func (s *SchedulerService) executeCustomScript(ctx context.Context, task models.ScheduledTask) (string, error) {
	var config models.CustomScriptConfig
	if err := json.Unmarshal([]byte(task.Config), &config); err != nil {
		return "", fmt.Errorf("è§£æä»»åŠ¡é…ç½®å¤±è´¥: %w", err)
	}

	// éªŒè¯è„šæœ¬é…ç½®
	if err := s.customScript.ValidateScript(config); err != nil {
		return "", fmt.Errorf("è„šæœ¬é…ç½®éªŒè¯å¤±è´¥: %w", err)
	}

	return s.customScript.ExecuteScript(ctx, config)
}

// ReloadTasks é‡æ–°åŠ è½½ä»»åŠ¡
func (s *SchedulerService) ReloadTasks() error {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	if !s.running {
		return fmt.Errorf("è°ƒåº¦æœåŠ¡æœªè¿è¡Œ")
	}

	// åœæ­¢å½“å‰è°ƒåº¦å™¨
	ctx := s.cron.Stop()
	<-ctx.Done()

	// åˆ›å»ºæ–°çš„è°ƒåº¦å™¨
	s.cron = cron.New(cron.WithSeconds())

	// é‡æ–°åŠ è½½ä»»åŠ¡
	if err := s.loadTasks(); err != nil {
		return err
	}

	// å¯åŠ¨æ–°è°ƒåº¦å™¨
	s.cron.Start()

	log.Printf("ğŸ”„ å®šæ—¶ä»»åŠ¡é‡æ–°åŠ è½½å®Œæˆ")
	return nil
}

// GetTaskStats è·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯
func (s *SchedulerService) GetTaskStats() (*models.TaskStats, error) {
	stats := &models.TaskStats{}

	// ç»Ÿè®¡ä»»åŠ¡æ•°é‡
	if err := s.db.Session(&gorm.Session{Logger: s.db.Logger.LogMode(logger.Silent)}).
		Model(&models.ScheduledTask{}).Count(&stats.TotalTasks).Error; err != nil {
		return nil, fmt.Errorf("ç»Ÿè®¡æ€»ä»»åŠ¡æ•°å¤±è´¥: %w", err)
	}

	if err := s.db.Session(&gorm.Session{Logger: s.db.Logger.LogMode(logger.Silent)}).
		Model(&models.ScheduledTask{}).Where("enabled = ?", true).Count(&stats.EnabledTasks).Error; err != nil {
		return nil, fmt.Errorf("ç»Ÿè®¡å¯ç”¨ä»»åŠ¡æ•°å¤±è´¥: %w", err)
	}

	// ç»Ÿè®¡æ‰§è¡Œè®°å½•
	if err := s.db.Session(&gorm.Session{Logger: s.db.Logger.LogMode(logger.Silent)}).
		Model(&models.TaskExecution{}).Count(&stats.TotalExecutions).Error; err != nil {
		return nil, fmt.Errorf("ç»Ÿè®¡æ€»æ‰§è¡Œæ•°å¤±è´¥: %w", err)
	}

	if err := s.db.Session(&gorm.Session{Logger: s.db.Logger.LogMode(logger.Silent)}).
		Model(&models.TaskExecution{}).Where("status = ?", models.TaskStatusSuccess).Count(&stats.SuccessExecutions).Error; err != nil {
		return nil, fmt.Errorf("ç»Ÿè®¡æˆåŠŸæ‰§è¡Œæ•°å¤±è´¥: %w", err)
	}

	if err := s.db.Session(&gorm.Session{Logger: s.db.Logger.LogMode(logger.Silent)}).
		Model(&models.TaskExecution{}).Where("status = ?", models.TaskStatusFailed).Count(&stats.FailedExecutions).Error; err != nil {
		return nil, fmt.Errorf("ç»Ÿè®¡å¤±è´¥æ‰§è¡Œæ•°å¤±è´¥: %w", err)
	}

	// è®¡ç®—æˆåŠŸç‡
	if stats.TotalExecutions > 0 {
		stats.SuccessRate = float64(stats.SuccessExecutions) / float64(stats.TotalExecutions) * 100
	}

	// è·å–æœ€è¿‘æ‰§è¡Œå’Œä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
	var lastExecution models.TaskExecution
	if err := s.db.Session(&gorm.Session{Logger: s.db.Logger.LogMode(logger.Silent)}).
		Order("started_at DESC").First(&lastExecution).Error; err == nil {
		stats.LastExecutionAt = &lastExecution.StartedAt
	}

	var nextTask models.ScheduledTask
	if err := s.db.Session(&gorm.Session{Logger: s.db.Logger.LogMode(logger.Silent)}).
		Where("enabled = ? AND next_run_at IS NOT NULL", true).
		Order("next_run_at ASC").First(&nextTask).Error; err == nil {
		stats.NextExecutionAt = nextTask.NextRunAt
	}

	// ç»Ÿè®¡æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡æ•°
	s.mutex.RLock()
	stats.RunningTasks = int64(len(s.taskExecs))
	s.mutex.RUnlock()

	return stats, nil
}

// GetRunningTasks è·å–æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡åˆ—è¡¨
func (s *SchedulerService) GetRunningTasks() []uint {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	taskIDs := make([]uint, 0, len(s.taskExecs))
	for taskID := range s.taskExecs {
		taskIDs = append(taskIDs, taskID)
	}

	return taskIDs
}

// GetDB è·å–æ•°æ®åº“è¿æ¥ï¼ˆç”¨äºhandlerï¼‰
func (s *SchedulerService) GetDB() *gorm.DB {
	return s.db
}

// GetTelemetryService è·å–é¥æµ‹æœåŠ¡ï¼ˆç”¨äºhandlerï¼‰
func (s *SchedulerService) GetTelemetryService() *TelemetryService {
	return s.telemetry
}

// GetCustomScriptService è·å–è‡ªå®šä¹‰è„šæœ¬æœåŠ¡ï¼ˆç”¨äºhandlerï¼‰
func (s *SchedulerService) GetCustomScriptService() *CustomScriptService {
	return s.customScript
}

// CreateTask åˆ›å»ºä»»åŠ¡
func (s *SchedulerService) CreateTask(task *models.ScheduledTask) error {
	if err := s.db.Create(task).Error; err != nil {
		return err
	}

	// å¦‚æœå¯ç”¨ï¼Œé‡æ–°åŠ è½½ä»»åŠ¡
	if task.Enabled && s.running {
		return s.ReloadTasks()
	}

	return nil
}

// UpdateTask æ›´æ–°ä»»åŠ¡
func (s *SchedulerService) UpdateTask(task *models.ScheduledTask) error {
	if err := s.db.Save(task).Error; err != nil {
		return err
	}

	// é‡æ–°åŠ è½½ä»»åŠ¡
	if s.running {
		return s.ReloadTasks()
	}

	return nil
}

// DeleteTask åˆ é™¤ä»»åŠ¡
func (s *SchedulerService) DeleteTask(taskID uint) error {
	if err := s.db.Delete(&models.ScheduledTask{}, taskID).Error; err != nil {
		return err
	}

	// é‡æ–°åŠ è½½ä»»åŠ¡
	if s.running {
		return s.ReloadTasks()
	}

	return nil
}

// GetTask è·å–å•ä¸ªä»»åŠ¡
func (s *SchedulerService) GetTask(taskID uint) (*models.ScheduledTask, error) {
	var task models.ScheduledTask
	if err := s.db.First(&task, taskID).Error; err != nil {
		return nil, err
	}
	return &task, nil
}

// GetTasks è·å–ä»»åŠ¡åˆ—è¡¨
func (s *SchedulerService) GetTasks(offset, limit int, taskType, status string) ([]models.ScheduledTask, int64, error) {
	var tasks []models.ScheduledTask
	var total int64

	query := s.db.Model(&models.ScheduledTask{})

	if taskType != "" {
		query = query.Where("type = ?", taskType)
	}
	if status != "" {
		if status == "enabled" {
			query = query.Where("enabled = ?", true)
		} else if status == "disabled" {
			query = query.Where("enabled = ?", false)
		}
	}

	query.Count(&total)

	err := query.Offset(offset).Limit(limit).Order("created_at DESC").Find(&tasks).Error
	return tasks, total, err
}

// GetTaskExecutions è·å–ä»»åŠ¡æ‰§è¡Œå†å²
func (s *SchedulerService) GetTaskExecutions(taskID uint, offset, limit int) ([]models.TaskExecution, int64, error) {
	var executions []models.TaskExecution
	var total int64

	query := s.db.Model(&models.TaskExecution{}).Where("task_id = ?", taskID)
	query.Count(&total)

	err := query.Preload("Task").Offset(offset).Limit(limit).Order("started_at DESC").Find(&executions).Error
	return executions, total, err
}

// ExecuteTaskManually æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡
func (s *SchedulerService) ExecuteTaskManually(task models.ScheduledTask) error {
	log.Printf("ğŸ”§ æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡: %s (ID: %d)", task.Name, task.ID)

	// æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²åœ¨æ‰§è¡Œ
	s.mutex.RLock()
	if _, exists := s.taskExecs[task.ID]; exists {
		s.mutex.RUnlock()
		return fmt.Errorf("ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­")
	}
	s.mutex.RUnlock()

	// åœ¨åå°æ‰§è¡Œä»»åŠ¡
	go s.executeTask(task)
	return nil
}

// initializeDefaultTasks åˆå§‹åŒ–é»˜è®¤ä»»åŠ¡
func (s *SchedulerService) initializeDefaultTasks() error {
	// åˆ›å»ºé»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡
	if err := s.createDefaultNodeBackupTask(); err != nil {
		log.Printf("âš ï¸ åˆ›å»ºé»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡å¤±è´¥: %v", err)
	}
	
	// åˆ›å»ºé»˜è®¤æ—¥å¿—æ¸…ç†ä»»åŠ¡
	if err := s.createDefaultLogCleanupTask(); err != nil {
		log.Printf("âš ï¸ åˆ›å»ºé»˜è®¤æ—¥å¿—æ¸…ç†ä»»åŠ¡å¤±è´¥: %v", err)
	}
	
	return nil
}

// createDefaultNodeBackupTask åˆ›å»ºé»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡
func (s *SchedulerService) createDefaultNodeBackupTask() error {
	// æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨é»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡
	var count int64
	if err := s.db.Model(&models.ScheduledTask{}).
		Where("name = ? AND type = ?", "é»˜è®¤èŠ‚ç‚¹å¤‡ä»½", models.TaskTypeNodeBackup).
		Count(&count).Error; err != nil {
		return fmt.Errorf("æ£€æŸ¥é»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡å¤±è´¥: %w", err)
	}
	
	// å¦‚æœå·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡åˆ›å»º
	if count > 0 {
		log.Printf("ğŸ“‹ é»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
		return nil
	}
	
	// åˆ›å»ºé»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡é…ç½®
	defaultConfig := models.NodeBackupConfig{
		StorageType:   "local",
		LocalPath:     "/etc/smartdns/backups",
		NodeIDs:       []uint{},
		BackupConfigs: true,
		BackupLogs:    false,
		Compression:   true,
		RetentionDays: 30,
	}
	
	// åºåˆ—åŒ–é…ç½®
	configJSON, err := json.Marshal(defaultConfig)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–é»˜è®¤èŠ‚ç‚¹å¤‡ä»½é…ç½®å¤±è´¥: %w", err)
	}
	
	// åˆ›å»ºé»˜è®¤ä»»åŠ¡
	defaultTask := &models.ScheduledTask{
		Name:        "é»˜è®¤èŠ‚ç‚¹å¤‡ä»½",
		Type:        models.TaskTypeNodeBackup,
		Description: "ç³»ç»Ÿé»˜è®¤åˆ›å»ºçš„èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡ï¼Œæ¯å¤©å‡Œæ™¨3ç‚¹è‡ªåŠ¨æ‰§è¡Œ",
		CronExpr:    "0 0 3 * * *", // æ¯å¤©å‡Œæ™¨3ç‚¹æ‰§è¡Œ
		Config:      string(configJSON),
		Enabled:     true,
	}
	
	if err := s.db.Create(defaultTask).Error; err != nil {
		return fmt.Errorf("åˆ›å»ºé»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡å¤±è´¥: %w", err)
	}
	
	log.Printf("âœ… å·²åˆ›å»ºé»˜è®¤èŠ‚ç‚¹å¤‡ä»½ä»»åŠ¡ (ID: %d)", defaultTask.ID)
	return nil
}

// createDefaultLogCleanupTask åˆ›å»ºé»˜è®¤æ—¥å¿—æ¸…ç†ä»»åŠ¡
func (s *SchedulerService) createDefaultLogCleanupTask() error {
	// æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨é»˜è®¤æ—¥å¿—æ¸…ç†ä»»åŠ¡
	var count int64
	if err := s.db.Model(&models.ScheduledTask{}).
		Where("name = ? AND type = ?", "é»˜è®¤SmartDNSæ—¥å¿—æ¸…ç†", models.TaskTypeLogCleanup).
		Count(&count).Error; err != nil {
		return fmt.Errorf("æ£€æŸ¥é»˜è®¤æ—¥å¿—æ¸…ç†ä»»åŠ¡å¤±è´¥: %w", err)
	}
	
	// å¦‚æœå·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡åˆ›å»º
	if count > 0 {
		log.Printf("ğŸ“‹ é»˜è®¤æ—¥å¿—æ¸…ç†ä»»åŠ¡å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
		return nil
	}
	
	// åˆ›å»ºé»˜è®¤æ—¥å¿—æ¸…ç†ä»»åŠ¡é…ç½®
	defaultConfig := models.LogCleanupConfig{
		AgentLogDays:    7,  // agentæ—¥å¿—ä¿ç•™7å¤©
		BackendLogDays:  7,  // backendæ—¥å¿—ä¿ç•™7å¤©
		SmartDNSLogDays: 30, // SmartDNSæ—¥å¿—ä¿ç•™30å¤©
		LogPaths:        []string{}, // ä½¿ç”¨é»˜è®¤è·¯å¾„
	}
	
	// åºåˆ—åŒ–é…ç½®
	configJSON, err := json.Marshal(defaultConfig)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–é»˜è®¤æ—¥å¿—æ¸…ç†é…ç½®å¤±è´¥: %w", err)
	}
	
	// åˆ›å»ºé»˜è®¤ä»»åŠ¡
	defaultTask := &models.ScheduledTask{
		Name:        "é»˜è®¤SmartDNSæ—¥å¿—æ¸…ç†",
		Type:        models.TaskTypeLogCleanup,
		Description: "ç³»ç»Ÿé»˜è®¤åˆ›å»ºçš„SmartDNSæ—¥å¿—æ¸…ç†ä»»åŠ¡ï¼Œæ¯å¤©å‡Œæ™¨2ç‚¹è‡ªåŠ¨æ‰§è¡Œï¼Œä¿ç•™30å¤©å†…çš„æ—¥å¿—",
		CronExpr:    "0 0 2 * * *", // æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
		Config:      string(configJSON),
		Enabled:     true,
	}
	
	if err := s.db.Create(defaultTask).Error; err != nil {
		return fmt.Errorf("åˆ›å»ºé»˜è®¤æ—¥å¿—æ¸…ç†ä»»åŠ¡å¤±è´¥: %w", err)
	}
	
	log.Printf("âœ… å·²åˆ›å»ºé»˜è®¤SmartDNSæ—¥å¿—æ¸…ç†ä»»åŠ¡ (ID: %d)", defaultTask.ID)
	return nil
}
