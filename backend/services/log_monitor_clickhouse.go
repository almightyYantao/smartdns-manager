package services

import (
	"bufio"
	"context"
	"fmt"
	"log"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"time"

	"golang.org/x/crypto/ssh"
	"gorm.io/gorm"

	"smartdns-manager/database"
	"smartdns-manager/models"
)

// LogMonitorServiceCH ClickHouse ç‰ˆæœ¬çš„æ—¥å¿—ç›‘æ§æœåŠ¡
type LogMonitorServiceCH struct {
	db          *gorm.DB
	monitors    map[uint]*NodeMonitorCH
	mu          sync.RWMutex
	batchSize   int
	flushTicker *time.Ticker
	logRegex    *regexp.Regexp
}

// NodeMonitorCH å•ä¸ªèŠ‚ç‚¹çš„ç›‘æ§å™¨
type NodeMonitorCH struct {
	nodeID      uint
	node        *models.Node
	sshClient   *SSHClient
	ctx         context.Context
	cancel      context.CancelFunc
	isRunning   bool
	logRegex    *regexp.Regexp
	batchBuffer []*models.DNSLogCK
	mu          sync.Mutex
}

// NewLogMonitorServiceCH åˆ›å»º ClickHouse ç‰ˆæœ¬çš„æ—¥å¿—ç›‘æ§æœåŠ¡
func NewLogMonitorServiceCH(db *gorm.DB) *LogMonitorServiceCH {
	if db == nil {
		log.Fatal("âŒ database connection is nil")
	}

	logRegex := regexp.MustCompile(`\[([^\]]+)\]\s+(\S+)\s+query\s+(\S+),\s+type\s+(\d+),\s+time\s+(\d+)ms,\s+speed:\s+([-\d.]+)ms,\s+result\s*(.*)`)

	service := &LogMonitorServiceCH{
		db:          db,
		monitors:    make(map[uint]*NodeMonitorCH),
		batchSize:   1000,                            // ClickHouse å¯ä»¥å¤„ç†æ›´å¤§çš„æ‰¹æ¬¡
		flushTicker: time.NewTicker(2 * time.Second), // 2ç§’åˆ·æ–°ä¸€æ¬¡
		logRegex:    logRegex,
	}

	// å¯åŠ¨æ‰¹é‡åˆ·æ–°åç¨‹
	// go service.flushLoop()

	log.Println("âœ… ClickHouse æ—¥å¿—ç›‘æ§æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
	return service
}

// flushLoop å®šæ—¶åˆ·æ–°æ‰€æœ‰èŠ‚ç‚¹çš„æ‰¹é‡æ•°æ®
func (s *LogMonitorServiceCH) flushLoop() {
	for range s.flushTicker.C {
		s.mu.RLock()
		monitors := make([]*NodeMonitorCH, 0, len(s.monitors))
		for _, monitor := range s.monitors {
			monitors = append(monitors, monitor)
		}
		s.mu.RUnlock()

		for _, monitor := range monitors {
			monitor.flushBatch()
		}
	}
}

// StartNodeMonitor å¯åŠ¨æŒ‡å®šèŠ‚ç‚¹çš„æ—¥å¿—ç›‘æ§
func (s *LogMonitorServiceCH) StartNodeMonitor(nodeID uint) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	log.Printf("ğŸš€ å°è¯•å¯åŠ¨èŠ‚ç‚¹ %d çš„ç›‘æ§", nodeID)

	// æ£€æŸ¥æ˜¯å¦å·²åœ¨è¿è¡Œ
	if monitor, exists := s.monitors[nodeID]; exists && monitor.isRunning {
		log.Printf("âš ï¸ èŠ‚ç‚¹ %d çš„ç›‘æ§å·²åœ¨è¿è¡Œ", nodeID)
		return fmt.Errorf("èŠ‚ç‚¹ %d çš„ç›‘æ§å·²åœ¨è¿è¡Œ", nodeID)
	}

	// è·å–èŠ‚ç‚¹ä¿¡æ¯
	var node models.Node
	if err := s.db.First(&node, nodeID).Error; err != nil {
		log.Printf("âŒ èŠ‚ç‚¹ %d ä¸å­˜åœ¨: %v", nodeID, err)
		return fmt.Errorf("èŠ‚ç‚¹ä¸å­˜åœ¨: %w", err)
	}

	log.Printf("ğŸ“ èŠ‚ç‚¹ä¿¡æ¯: %s (%s:%d)", node.Name, node.Host, node.Port)

	// åˆ›å»º SSH å®¢æˆ·ç«¯
	sshClient, err := NewSSHClient(&node)
	if err != nil {
		log.Printf("âŒ SSHè¿æ¥å¤±è´¥: %v", err)
		return fmt.Errorf("SSHè¿æ¥å¤±è´¥: %w", err)
	}

	// æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	logPath := node.LogPath
	if logPath == "" {
		logPath = "/var/log/audit/audit.log"
	}

	log.Printf("ğŸ“‚ æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: %s", logPath)

	checkCmd := fmt.Sprintf("test -f %s && echo 'exists' || echo 'not found'", logPath)
	output, err := sshClient.ExecuteCommand(checkCmd)
	log.Printf("ğŸ“„ æ–‡ä»¶æ£€æŸ¥ç»“æœ: %s", strings.TrimSpace(output))

	if err != nil || !strings.Contains(output, "exists") {
		sshClient.Close()
		log.Printf("âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: %s", logPath)
		return fmt.Errorf("æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: %s", logPath)
	}

	// åˆ›å»ºç›‘æ§å™¨
	ctx, cancel := context.WithCancel(context.Background())
	monitor := &NodeMonitorCH{
		nodeID:      nodeID,
		node:        &node,
		sshClient:   sshClient,
		ctx:         ctx,
		cancel:      cancel,
		isRunning:   true,
		logRegex:    s.logRegex,
		batchBuffer: make([]*models.DNSLogCK, 0, s.batchSize),
	}

	s.monitors[nodeID] = monitor

	// å¯åŠ¨ç›‘æ§åç¨‹
	go monitor.startMonitoring(s.batchSize)

	// å¯åŠ¨ç‹¬ç«‹çš„åˆ·æ–°åç¨‹
	go monitor.autoFlushLoop()

	// æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
	s.db.Model(&models.Node{}).Where("id = ?", nodeID).Updates(map[string]interface{}{
		"log_monitor_enabled": true,
	})

	log.Printf("âœ… èŠ‚ç‚¹ %d (%s) çš„æ—¥å¿—ç›‘æ§å·²å¯åŠ¨", nodeID, node.Name)
	return nil
}

// autoFlushLoop æ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹çš„è‡ªåŠ¨åˆ·æ–°åç¨‹
func (m *NodeMonitorCH) autoFlushLoop() {
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-m.ctx.Done():
			return
		case <-ticker.C:
			m.flushBatch()
		}
	}
}

// StopNodeMonitor åœæ­¢æŒ‡å®šèŠ‚ç‚¹çš„æ—¥å¿—ç›‘æ§
func (s *LogMonitorServiceCH) StopNodeMonitor(nodeID uint) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	monitor, exists := s.monitors[nodeID]
	if !exists || !monitor.isRunning {
		return fmt.Errorf("èŠ‚ç‚¹ %d çš„ç›‘æ§æœªè¿è¡Œ", nodeID)
	}

	// åœæ­¢ç›‘æ§
	monitor.stop()
	delete(s.monitors, nodeID)

	// æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
	s.db.Model(&models.Node{}).Where("id = ?", nodeID).Updates(map[string]interface{}{
		"log_monitor_enabled": false,
	})

	log.Printf("âœ… å·²åœæ­¢èŠ‚ç‚¹ %d çš„ç›‘æ§", nodeID)
	return nil
}

// GetNodeMonitorStatus è·å–èŠ‚ç‚¹ç›‘æ§çŠ¶æ€
func (s *LogMonitorServiceCH) GetNodeMonitorStatus(nodeID uint) (bool, error) {
	s.mu.RLock()
	defer s.mu.RUnlock()

	monitor, exists := s.monitors[nodeID]
	if !exists {
		return false, nil
	}
	return monitor.isRunning, nil
}

// StopAll åœæ­¢æ‰€æœ‰ç›‘æ§
func (s *LogMonitorServiceCH) StopAll() {
	s.mu.Lock()
	defer s.mu.Unlock()

	for nodeID, monitor := range s.monitors {
		monitor.stop()
		log.Printf("âœ… å·²åœæ­¢èŠ‚ç‚¹ %d çš„ç›‘æ§", nodeID)
	}
	s.monitors = make(map[uint]*NodeMonitorCH)
	s.flushTicker.Stop()
}

// startMonitoring å¼€å§‹ç›‘æ§ï¼ˆåœ¨ SSH ä¸Šæ‰§è¡Œ tail -fï¼‰
func (m *NodeMonitorCH) startMonitoring(batchSize int) {
	defer func() {
		m.isRunning = false
		m.sshClient.Close()
		log.Printf("ğŸ›‘ èŠ‚ç‚¹ %d ç›‘æ§å·²åœæ­¢", m.nodeID)
	}()

	logPath := m.node.LogPath
	if logPath == "" {
		logPath = "/var/log/audit/audit.log"
	}

	// ä½¿ç”¨ tail -f -n 0 åªè¯»å–æ–°å¢æ—¥å¿—
	cmd := fmt.Sprintf("tail -f -n 0 %s", logPath)

	log.Printf("ğŸ”„ æ‰§è¡Œå‘½ä»¤: %s", cmd)

	session, err := m.sshClient.client.NewSession()
	if err != nil {
		log.Printf("âŒ åˆ›å»ºSSHä¼šè¯å¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
		return
	}
	defer session.Close()

	stdout, err := session.StdoutPipe()
	if err != nil {
		log.Printf("âŒ è·å–æ ‡å‡†è¾“å‡ºå¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
		return
	}

	if err := session.Start(cmd); err != nil {
		log.Printf("âŒ æ‰§è¡Œå‘½ä»¤å¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
		return
	}

	log.Printf("âœ… å¼€å§‹ç›‘æ§èŠ‚ç‚¹ %d çš„æ—¥å¿—", m.nodeID)

	scanner := bufio.NewScanner(stdout)
	lineCount := 0

	for {
		select {
		case <-m.ctx.Done():
			log.Printf("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å· (èŠ‚ç‚¹%d)", m.nodeID)
			session.Signal(ssh.SIGTERM)
			return
		default:
			if scanner.Scan() {
				line := strings.TrimSpace(scanner.Text())
				lineCount++

				// æ¯å¤„ç† 100 è¡Œæ‰“å°ä¸€æ¬¡æ—¥å¿—
				if lineCount%5000 == 0 {
					log.Printf("ğŸ“Š èŠ‚ç‚¹ %d å·²å¤„ç† %d è¡Œæ—¥å¿—", m.nodeID, lineCount)
				}

				if dnsLog := m.parseLine(line); dnsLog != nil {
					dnsLog.NodeID = uint32(m.nodeID)
					m.addToBatch(dnsLog)

					// è¾¾åˆ°æ‰¹é‡å¤§å°ï¼Œç«‹å³åˆ·æ–°
					if len(m.batchBuffer) >= batchSize {
						log.Printf("ğŸ’¾ èŠ‚ç‚¹ %d æ‰¹é‡ç¼“å†²åŒºå·²æ»¡ (%d æ¡)ï¼Œå¼€å§‹å†™å…¥", m.nodeID, len(m.batchBuffer))
						m.flushBatch()
					}
				}
			}

			if err := scanner.Err(); err != nil {
				log.Printf("âŒ è¯»å–æ—¥å¿—å‡ºé”™ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
				return
			}
		}
	}
}

// stop åœæ­¢ç›‘æ§
func (m *NodeMonitorCH) stop() {
	m.cancel()
	m.flushBatch() // åˆ·æ–°å‰©ä½™æ•°æ®
	m.isRunning = false
}

// addToBatch æ·»åŠ åˆ°æ‰¹é‡ç¼“å†²åŒº
func (m *NodeMonitorCH) addToBatch(dnsLog *models.DNSLogCK) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.batchBuffer = append(m.batchBuffer, dnsLog)
}

// flushBatch æ‰¹é‡æ’å…¥åˆ° ClickHouse
func (m *NodeMonitorCH) flushBatch() {
	m.mu.Lock()
	defer m.mu.Unlock()

	if len(m.batchBuffer) == 0 {
		return
	}

	batchCount := len(m.batchBuffer)
	log.Printf("ğŸ’¾ å‡†å¤‡å†™å…¥ %d æ¡æ—¥å¿—åˆ° ClickHouse (èŠ‚ç‚¹%d)", batchCount, m.nodeID)

	ctx := context.Background()
	batch, err := database.CHConn.PrepareBatch(ctx,
		"INSERT INTO dns_query_log (timestamp, date, node_id, client_ip, domain, query_type, time_ms, speed_ms, result_count, result_ips, raw_log)")

	if err != nil {
		log.Printf("âŒ å‡†å¤‡æ‰¹æ¬¡å¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
		return
	}

	startTime := time.Now()
	successCount := 0

	for _, dnsLog := range m.batchBuffer {
		err := batch.Append(
			dnsLog.Timestamp,
			dnsLog.Date,
			dnsLog.NodeID,
			dnsLog.ClientIP,
			dnsLog.Domain,
			dnsLog.QueryType,
			dnsLog.TimeMs,
			dnsLog.SpeedMs,
			dnsLog.ResultCount,
			dnsLog.ResultIPs,
			dnsLog.RawLog,
		)
		if err != nil {
			log.Printf("âŒ æ·»åŠ è®°å½•å¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
		} else {
			successCount++
		}
	}

	if err := batch.Send(); err != nil {
		log.Printf("âŒ å‘é€æ‰¹æ¬¡å¤±è´¥ (èŠ‚ç‚¹%d): %v", m.nodeID, err)
	} else {
		duration := time.Since(startTime)
		log.Printf("âœ… æˆåŠŸæ’å…¥ %d/%d æ¡æ—¥å¿—åˆ° ClickHouse (èŠ‚ç‚¹%d), è€—æ—¶: %v", successCount, batchCount, m.nodeID, duration)
	}

	m.batchBuffer = make([]*models.DNSLogCK, 0, 1000)
}

// parseLine è§£ææ—¥å¿—è¡Œ
func (m *NodeMonitorCH) parseLine(line string) *models.DNSLogCK {
	if line == "" {
		return nil
	}

	matches := m.logRegex.FindStringSubmatch(line)
	if matches == nil || len(matches) < 8 {
		return nil
	}

	// è§£ææ—¶é—´æˆ³ - æŒ‡å®šä½¿ç”¨ UTC æ—¶åŒº
	var timestamp time.Time
	var err error

	// å°è¯•è§£æå¸¦æ¯«ç§’çš„æ ¼å¼
	timestamp, err = time.ParseInLocation("2006-01-02 15:04:05,000", matches[1], time.UTC)
	if err != nil {
		// å¦‚æœå¤±è´¥ï¼Œå°è¯•ä¸å¸¦æ¯«ç§’çš„æ ¼å¼
		timestamp, err = time.ParseInLocation("2006-01-02 15:04:05", matches[1][:19], time.UTC)
		if err != nil {
			log.Printf("âš ï¸ è§£ææ—¶é—´å¤±è´¥: %s, error: %v", matches[1], err)
			return nil
		}
	}

	queryType, _ := strconv.Atoi(matches[4])
	timeMs, _ := strconv.Atoi(matches[5])
	speedMs, _ := strconv.ParseFloat(matches[6], 32)

	resultStr := strings.TrimSpace(matches[7])
	var resultIPs []string
	if resultStr != "" {
		resultIPs = strings.Split(resultStr, ",")
		for i := range resultIPs {
			resultIPs[i] = strings.TrimSpace(resultIPs[i])
		}
	}

	return &models.DNSLogCK{
		Timestamp:   timestamp,
		Date:        time.Date(timestamp.Year(), timestamp.Month(), timestamp.Day(), 0, 0, 0, 0, timestamp.Location()),
		ClientIP:    matches[2],
		Domain:      matches[3],
		QueryType:   uint16(queryType),
		TimeMs:      uint32(timeMs),
		SpeedMs:     float32(speedMs),
		ResultCount: uint8(len(resultIPs)),
		ResultIPs:   resultIPs,
		RawLog:      line,
	}
}

// GetLogs æŸ¥è¯¢æ—¥å¿—
func (s *LogMonitorServiceCH) GetLogs(page, pageSize int, filters map[string]interface{}) ([]models.DNSLog, int64, error) {
	ctx := context.Background()

	// æ„å»ºæŸ¥è¯¢æ¡ä»¶
	where := []string{"1=1"}
	args := []interface{}{}

	if nodeID, ok := filters["node_id"].(uint); ok {
		where = append(where, "node_id = ?")
		args = append(args, uint32(nodeID))
	}

	if clientIP, ok := filters["client_ip"].(string); ok && clientIP != "" {
		where = append(where, "client_ip = ?")
		args = append(args, clientIP)
	}

	if domain, ok := filters["domain"].(string); ok && domain != "" {
		where = append(where, "domain LIKE ?")
		args = append(args, "%"+domain+"%")
	}

	if queryType, ok := filters["query_type"].(int); ok {
		where = append(where, "query_type = ?")
		args = append(args, uint16(queryType))
	}

	if startTime, ok := filters["start_time"].(time.Time); ok {
		where = append(where, "timestamp >= ?")
		args = append(args, startTime)
	}

	if endTime, ok := filters["end_time"].(time.Time); ok {
		where = append(where, "timestamp <= ?")
		args = append(args, endTime)
	}

	whereClause := strings.Join(where, " AND ")

	// æŸ¥è¯¢æ€»æ•°
	var total uint64
	countQuery := fmt.Sprintf("SELECT count() FROM dns_query_log WHERE %s", whereClause)
	err := database.CHConn.QueryRow(ctx, countQuery, args...).Scan(&total)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢æ€»æ•°å¤±è´¥: %v", err)
		return nil, 0, err
	}

	// æŸ¥è¯¢æ•°æ®
	offset := (page - 1) * pageSize
	dataQuery := fmt.Sprintf(
		"SELECT timestamp, node_id, client_ip, domain, query_type, time_ms, speed_ms, result_count, result_ips, raw_log "+
			"FROM dns_query_log WHERE %s ORDER BY timestamp DESC LIMIT %d OFFSET %d",
		whereClause, pageSize, offset)

	rows, err := database.CHConn.Query(ctx, dataQuery, args...)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢æ•°æ®å¤±è´¥: %v", err)
		return nil, 0, err
	}
	defer rows.Close()

	var logs []models.DNSLog
	for rows.Next() {
		var logCK models.DNSLogCK
		err := rows.Scan(
			&logCK.Timestamp,
			&logCK.NodeID,
			&logCK.ClientIP,
			&logCK.Domain,
			&logCK.QueryType,
			&logCK.TimeMs,
			&logCK.SpeedMs,
			&logCK.ResultCount,
			&logCK.ResultIPs,
			&logCK.RawLog,
		)
		if err != nil {
			log.Printf("âš ï¸ æ‰«æè¡Œå¤±è´¥: %v", err)
			continue
		}

		// è½¬æ¢ä¸ºé€šç”¨æ ¼å¼
		log := models.DNSLog{
			NodeID:    uint(logCK.NodeID),
			Timestamp: logCK.Timestamp,
			ClientIP:  logCK.ClientIP,
			Domain:    logCK.Domain,
			QueryType: int(logCK.QueryType),
			TimeMs:    int(logCK.TimeMs),
			SpeedMs:   float64(logCK.SpeedMs),
			Result:    strings.Join(logCK.ResultIPs, ", "),
			ResultIPs: strings.Join(logCK.ResultIPs, ","),
			IPCount:   int(logCK.ResultCount),
			RawLog:    logCK.RawLog,
		}
		logs = append(logs, log)
	}

	log.Printf("âœ… æˆåŠŸæŸ¥è¯¢ %d æ¡æ—¥å¿—ï¼Œæ€»æ•°: %d", len(logs), total)
	return logs, int64(total), nil
}

// GetNodeStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (s *LogMonitorServiceCH) GetNodeStats(nodeID uint, startTime, endTime time.Time) (*models.DNSLogStats, error) {
	ctx := context.Background()
	stats := &models.DNSLogStats{
		TopDomains:  make([]models.DomainStat, 0),
		TopClients:  make([]models.ClientStat, 0),
		HourlyStats: make([]models.HourlyStat, 0),
	}

	startDate := startTime.Format("2006-01-02")
	endDate := endTime.Format("2006-01-02")
	nodeID32 := uint32(nodeID)

	// æ€»æŸ¥è¯¢æ•°
	var totalQueries uint64
	err := database.CHConn.QueryRow(ctx,
		"SELECT count() FROM dns_query_log WHERE node_id = ? AND date BETWEEN ? AND ?",
		nodeID32, startDate, endDate).Scan(&totalQueries)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢æ€»æ•°å¤±è´¥: %v", err)
		return nil, err
	}
	stats.TotalQueries = int64(totalQueries)

	// å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç›´æ¥è¿”å›ç©ºç»Ÿè®¡
	if totalQueries == 0 {
		log.Printf("âš ï¸ èŠ‚ç‚¹ %d åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æ²¡æœ‰æ—¥å¿—æ•°æ®", nodeID)
		return stats, nil
	}

	// å”¯ä¸€å®¢æˆ·ç«¯
	var uniqueClients uint64
	err = database.CHConn.QueryRow(ctx,
		"SELECT uniqExact(client_ip) FROM dns_query_log WHERE node_id = ? AND date BETWEEN ? AND ?",
		nodeID32, startDate, endDate).Scan(&uniqueClients)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢å”¯ä¸€å®¢æˆ·ç«¯å¤±è´¥: %v", err)
	} else {
		stats.UniqueClients = int64(uniqueClients)
	}

	// å”¯ä¸€åŸŸå
	var uniqueDomains uint64
	err = database.CHConn.QueryRow(ctx,
		"SELECT uniqExact(domain) FROM dns_query_log WHERE node_id = ? AND date BETWEEN ? AND ?",
		nodeID32, startDate, endDate).Scan(&uniqueDomains)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢å”¯ä¸€åŸŸåå¤±è´¥: %v", err)
	} else {
		stats.UniqueDomains = int64(uniqueDomains)
	}

	// å¹³å‡æŸ¥è¯¢æ—¶é—´ - å¤„ç† NaN æƒ…å†µ
	var avgQueryTime *float64 // ä½¿ç”¨æŒ‡é’ˆç±»å‹ï¼Œå¯ä»¥æ¥æ”¶ NULL
	err = database.CHConn.QueryRow(ctx,
		"SELECT avgOrNull(time_ms) FROM dns_query_log WHERE node_id = ? AND date BETWEEN ? AND ?",
		nodeID32, startDate, endDate).Scan(&avgQueryTime)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢å¹³å‡æ—¶é—´å¤±è´¥: %v", err)
	} else if avgQueryTime != nil {
		stats.AvgQueryTime = *avgQueryTime
	} else {
		stats.AvgQueryTime = 0 // NULL æ—¶è®¾ä¸º 0
	}

	// çƒ­é—¨åŸŸå
	rows, err := database.CHConn.Query(ctx,
		"SELECT domain, count() as count FROM dns_query_log "+
			"WHERE node_id = ? AND date BETWEEN ? AND ? "+
			"GROUP BY domain ORDER BY count DESC LIMIT 10",
		nodeID32, startDate, endDate)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢çƒ­é—¨åŸŸåå¤±è´¥: %v", err)
	} else {
		for rows.Next() {
			var stat models.DomainStat
			var count uint64
			if err := rows.Scan(&stat.Domain, &count); err != nil {
				log.Printf("âš ï¸ æ‰«æçƒ­é—¨åŸŸåå¤±è´¥: %v", err)
				continue
			}
			stat.Count = int64(count)
			stats.TopDomains = append(stats.TopDomains, stat)
		}
		rows.Close()
	}

	// çƒ­é—¨å®¢æˆ·ç«¯
	rows, err = database.CHConn.Query(ctx,
		"SELECT client_ip, count() as count FROM dns_query_log "+
			"WHERE node_id = ? AND date BETWEEN ? AND ? "+
			"GROUP BY client_ip ORDER BY count DESC LIMIT 10",
		nodeID32, startDate, endDate)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢çƒ­é—¨å®¢æˆ·ç«¯å¤±è´¥: %v", err)
	} else {
		for rows.Next() {
			var stat models.ClientStat
			var count uint64
			if err := rows.Scan(&stat.ClientIP, &count); err != nil {
				log.Printf("âš ï¸ æ‰«æçƒ­é—¨å®¢æˆ·ç«¯å¤±è´¥: %v", err)
				continue
			}
			stat.Count = int64(count)
			stats.TopClients = append(stats.TopClients, stat)
		}
		rows.Close()
	}

	// æŒ‰å°æ—¶ç»Ÿè®¡
	rows, err = database.CHConn.Query(ctx,
		"SELECT toHour(timestamp) as hour, count() as count FROM dns_query_log "+
			"WHERE node_id = ? AND timestamp BETWEEN ? AND ? "+
			"GROUP BY hour ORDER BY hour",
		nodeID32, startTime, endTime)
	if err != nil {
		log.Printf("âŒ æŸ¥è¯¢æŒ‰å°æ—¶ç»Ÿè®¡å¤±è´¥: %v", err)
	} else {
		for rows.Next() {
			var stat models.HourlyStat
			var count uint64
			if err := rows.Scan(&stat.Hour, &count); err != nil {
				log.Printf("âš ï¸ æ‰«ææŒ‰å°æ—¶ç»Ÿè®¡å¤±è´¥: %v", err)
				continue
			}
			stat.Count = int64(count)
			stats.HourlyStats = append(stats.HourlyStats, stat)
		}
		rows.Close()
	}

	log.Printf("âœ… æˆåŠŸè·å–èŠ‚ç‚¹ %d çš„ç»Ÿè®¡ä¿¡æ¯ (æ€»æŸ¥è¯¢æ•°: %d)", nodeID, totalQueries)
	return stats, nil
}

// CleanNodeLogs æ¸…ç†èŠ‚ç‚¹æ—§æ—¥å¿—
func (s *LogMonitorServiceCH) CleanNodeLogs(nodeID uint, days int) error {
	ctx := context.Background()
	cutoffDate := time.Now().AddDate(0, 0, -days).Format("2006-01-02")

	query := fmt.Sprintf(
		"ALTER TABLE dns_query_log DELETE WHERE node_id = %d AND date < '%s'",
		uint32(nodeID), cutoffDate)

	err := database.CHConn.Exec(ctx, query)
	if err != nil {
		log.Printf("âŒ æ¸…ç†èŠ‚ç‚¹ %d æ—§æ—¥å¿—å¤±è´¥: %v", nodeID, err)
		return err
	}

	log.Printf("âœ… æˆåŠŸæ¸…ç†èŠ‚ç‚¹ %d çš„ %d å¤©å‰çš„æ—¥å¿—", nodeID, days)
	return nil
}
